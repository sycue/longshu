# 龙书纪年：2023-03-15

> 这是朕的屏幕，上面闪烁着关于编程开发、人工智能、区块链等科技前沿的宝贵信息，不妨留心，吸收些许，别让那些世上的神秘之物逃脱我们掌控的魔爪。

---

## Bin-Huang/chatbox
- url: https://github.com/Bin-Huang/chatbox/
- date: "2023-03-15 10:51:50"
- tags: #clipper #ChatGPT
- tagline:  开源的 OpenAI API 跨平台桌面客户端

> ## Chatbox
> 
> *开源的 OpenAI API 跨平台桌面客户端，Prompt 的调试与管理工具，也可以用作 ChatGPT Plus 平替*
> 
> ## 为什么需要 ChatBox？
> 
> -   直接使用 OpenAI API 是比较困难的，需要了解编程与接口调用，而且用起来不够方便。ChatBox 可以帮助你处理所有的底层调用。
> -   ChatBox 还帮你在本地保存了所有的聊天记录和 prompt，防止在线服务的数据丢失。
> -   ChatBox 还可以帮助你设计、调试和管理 prompt，让你更好地操作 AI 模型。

---

## whoiskatrin/sql-translator: SQL Translator is a tool for converting natural language queries into SQL code using artificial intelligence. This project is 100% free and open source.
- url: https://github.com/whoiskatrin/sql-translator
- date: "2023-03-15 10:57:53"
- tags: #clipper #SQL #AI
- tagline:  将自然语言转换成SQL语句的AI工具

> SQL Translator is a tool for converting natural language queries into SQL code using artificial intelligence. This project is 100% free and open source.
> 
> [www.sqltranslate.app/](https://www.sqltranslate.app/)

---

## chathub-dev/chathub: All-in-one chatbot client
- url: https://github.com/chathub-dev/chathub
- date: "2023-03-15 10:59:46"
- tags: #clipper #ChatGPT
- tagline:  多合一AI聊天机器人聚合

> All-in-one chatbot client
> 
> [chathub.gg](https://chathub.gg/)

---

## GPT-4
- url: https://openai.com/research/gpt-4
- date: "2023-03-15 15:10:01"
- tags: #clipper #ChatGPT #OpenAI #GPT-4
- tagline:  今天GTP-4发布了，随处可见GPT-4的介绍文章，想看看OpenAI官方怎么说的，都在这里了。

> We’ve created GPT-4, the latest milestone in OpenAI’s effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.

我们创建了 GPT-4，这是 OpenAI 努力扩展深度学习的最新里程碑。GPT-4 是一个大型多模态模型（接受图像和文本输入，发出文本输出），虽然在许多现实世界场景中的能力不如人类，但在各种专业和学术基准上表现出人类水平的表现。


---

## 使用 LoRA 进行 Stable Diffusion 的高效参数微调
- url: https://baijiahao.baidu.com/s?id=1757415561282633196
- date: "2023-03-15 18:01:58"
- tags: #clipper #LoRA #StableDiffusion
- tagline:  什么是LoRA：用于处理大模型微调的一种技术

> LoRA: Low-Rank Adaptation of Large Language Models 是微软研究员引入的一项新技术，主要用于处理大模型微调的问题。目前超过数十亿以上参数的具有强能力的大模型 (例如 GPT-3) 通常在为了适应其下游任务的微调中会呈现出巨大开销。LoRA 建议冻结预训练模型的权重并在每个 Transformer 块中注入可训练层 (秩-分解矩阵)。因为不需要为大多数模型权重计算梯度，所以大大减少了需要训练参数的数量并且降低了 GPU 的内存要求。研究人员发现，通过聚焦大模型的 Transformer 注意力块，使用 LoRA 进行的微调质量与全模型微调相当，同时速度更快且需要更少的计算。
> 
> 尽管 LoRA 最初是为大模型提出的，并在 transformer 块上进行了演示，但该技术也可以应用于其他地方。在微调 Stable Diffusion 的情况下，LoRA 可以应用于将图像表示与描述它们的提示相关联的交叉注意层。
> 
> 英文原文: https://huggingface.co/blog/lora
> 原文作者: Pedro Cuenca, Sayak Paul

---

## Stable Diffusion爱好者常说的LoRa是什么？ 
- url: https://zhuanlan.zhihu.com/p/610031713
- date: "2023-03-16 14:11:23"
- tags: #clipper #StableDiffusion 
- tagline:  Stable Diffusion爱好者常说的LoRa是什么？

> ## Stable Diffusion爱好者常说的LoRa是什么？
> 
> LoRA，英文全称Low-Rank Adaptation of Large Language Models，直译为大语言模型的低阶适应，这是微软的研究人员为了解决大语言模型微调而开发的一项技术。
